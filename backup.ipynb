{"cells":[{"cell_type":"markdown","metadata":{"id":"rQfn_ADsb5qx"},"source":["# Import Libraires"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17832,"status":"ok","timestamp":1695022841939,"user":{"displayName":"Zeng Guangming","userId":"04186767812980264343"},"user_tz":-600},"id":"zcabxCbmb-_V","outputId":"604fce1b-092c-4e53-f635-bc228ed6ffad"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1695022517875,"user":{"displayName":"Yangbohan Miao","userId":"12088792683042047138"},"user_tz":-600},"id":"RiCkQR3r3uMX","outputId":"d09f0fc2-9c95-475b-e836-e8aea701c35c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon Sep 18 07:35:17 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   47C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1695022517875,"user":{"displayName":"Yangbohan Miao","userId":"12088792683042047138"},"user_tz":-600},"id":"QVEmpbBX3nqX","outputId":"9ea5567d-63a9-460a-9fd4-9b7b38814eb7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Your runtime has 13.6 gigabytes of available RAM\n","\n","Not using a high-RAM runtime\n"]}],"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1695022517875,"user":{"displayName":"Yangbohan Miao","userId":"12088792683042047138"},"user_tz":-600},"id":"xmqW2FW7gHcj","outputId":"b1fffccc-7b38-449f-97e3-af96428022b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n"]}],"source":["!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11679,"status":"ok","timestamp":1695022529552,"user":{"displayName":"Yangbohan Miao","userId":"12088792683042047138"},"user_tz":-600},"id":"TjbtOk-v_agZ","outputId":"519d4594-5cf4-44a2-a152-539eecd8466b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting chainer\n","  Downloading chainer-7.8.1.tar.gz (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from chainer) (67.7.2)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from chainer) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from chainer) (3.12.2)\n","Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from chainer) (1.23.5)\n","Requirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from chainer) (3.20.3)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from chainer) (1.16.0)\n","Building wheels for collected packages: chainer\n","  Building wheel for chainer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for chainer: filename=chainer-7.8.1-py3-none-any.whl size=967716 sha256=3f09121a5094ffa9d6b51fa66a2ea48ba153c6dd8da400ed2275cf0723d3e5d1\n","  Stored in directory: /root/.cache/pip/wheels/c4/95/6a/16014db6f761c4e742755b64aac60dbe142da1df6c5919f790\n","Successfully built chainer\n","Installing collected packages: chainer\n","Successfully installed chainer-7.8.1\n"]}],"source":["!pip install chainer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RW6Qmv53b5q4"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import keras\n","import cv2\n","from keras.models import Sequential\n","from keras.preprocessing.image import img_to_array\n","import os\n","from tqdm import tqdm\n","import re\n","import matplotlib.pyplot as plt\n","\n","from chainer import Chain\n","from chainer import functions as F\n","from chainer import links as L"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["parents_loc = \"/content/drive/MyDrive/ADV_CV_Code/\"\n","native_loc = \"/content/native/\"\n","\n","# if native_loc exists, then we are running on a local machine\n","if os.path.exists(native_loc):\n","    print(\"Native location exists\")\n","else:\n","    # create native_loc\n","    os.mkdir(native_loc)\n","    # copy all files from parents_loc to native_loc\n","    !cp -r $parents_loc* $native_loc\n","    print(\"Copied files from parents_loc to native_loc\")"]},{"cell_type":"markdown","metadata":{"id":"sJB30-TAb5q6"},"source":["# Load Data"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12401,"status":"ok","timestamp":1695023626387,"user":{"displayName":"Yangbohan Miao","userId":"12088792683042047138"},"user_tz":-600},"id":"3Vdcn9fvb5q7","outputId":"3e5cad2c-90cd-465a-c011-24fc98891b35"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 855/855 [00:11<00:00, 71.72it/s]\n"]}],"source":["parents_loc = \"/content/drive/MyDrive/ADV_CV_Code/\"\n","# to get the files in proper order\n","def sorted_alphanumeric(data):\n","    convert = lambda text: int(text) if text.isdigit() else text.lower()\n","    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]\n","    return sorted(data,key = alphanum_key)\n","# defining the size of the image\n","SIZE = 256\n","high_img = []\n","low_img = []\n","data_loc = parents_loc + 'Dataset/Raw Data/'\n","path = data_loc + 'high_res'\n","path_low = data_loc + 'low_res'\n","files = os.listdir(path)\n","files = sorted_alphanumeric(files)\n","for i in tqdm(files):\n","    if i == '855.jpg':\n","        break\n","    elif os.path.exists(path_low + '/'+i):\n","        img = cv2.imread(path + '/'+i,1)\n","        # open cv reads images in BGR format so we have to convert it to RGB\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        #resizing image\n","        img = cv2.resize(img, (SIZE, SIZE))\n","        img = img.astype('float32') / 255.0\n","        high_img.append(img_to_array(img))\n","\n","        img = cv2.imread(path_low + '/'+i,1)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        #resizing image\n","        img = cv2.resize(img, (SIZE, SIZE))\n","        img = img.astype('float32') / 255.0\n","        low_img.append(img_to_array(img))"]},{"cell_type":"markdown","metadata":{"id":"FimaAWP5b5q9"},"source":["# Data Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HDLkRJt9b5q9"},"outputs":[],"source":["for i in range(4):\n","    a = np.random.randint(0,855)\n","    plt.figure(figsize=(10,10))\n","    plt.subplot(1,2,1)\n","    plt.title('High Resolution Imge', color = 'green', fontsize = 20)\n","    plt.imshow(high_img[a])\n","    plt.axis('off')\n","    plt.subplot(1,2,2)\n","    plt.title('low Resolution Image ', color = 'black', fontsize = 20)\n","    plt.imshow(low_img[a])\n","    plt.axis('off')"]},{"cell_type":"markdown","metadata":{"id":"rtN4Cqb3b5q-"},"source":["# Slicing and Reshaping Images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T1BH2Crwb5q_"},"outputs":[],"source":["train_high_image = high_img[:700]\n","train_low_image = low_img[:700]\n","train_high_image = np.reshape(train_high_image,(len(train_high_image),SIZE,SIZE,3))\n","train_low_image = np.reshape(train_low_image,(len(train_low_image),SIZE,SIZE,3))\n","\n","validation_high_image = high_img[700:830]\n","validation_low_image = low_img[700:830]\n","validation_high_image= np.reshape(validation_high_image,(len(validation_high_image),SIZE,SIZE,3))\n","validation_low_image = np.reshape(validation_low_image,(len(validation_low_image),SIZE,SIZE,3))\n","\n","\n","test_high_image = high_img[830:]\n","test_low_image = low_img[830:]\n","test_high_image= np.reshape(test_high_image,(len(test_high_image),SIZE,SIZE,3))\n","test_low_image = np.reshape(test_low_image,(len(test_low_image),SIZE,SIZE,3))\n","\n","print(\"Shape of training images:\",train_high_image.shape)\n","print(\"Shape of test images:\",test_high_image.shape)\n","print(\"Shape of validation images:\",validation_high_image.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"txBk25Fab5rA"},"source":["# Defining Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lA4m8ikn1xYO"},"outputs":[],"source":["# GAN Model\n","class Generator(Chain):\n","    def __init__(self):\n","        super().__init__(\n","            fc=L.Linear(None, 256*2*2),\n","            dc1=L.Deconvolution2D(256, 128, 4, stride=2, pad=1),\n","            dc2=L.Deconvolution2D(128, 64, 4, stride=2, pad=1),\n","            dc3=L.Deconvolution2D(64, 32, 4, stride=2, pad=1),\n","            dc4=L.Deconvolution2D(32, 3, 4, stride=2, pad=1),\n","            bn0=L.BatchNormalization(256*2*2),\n","            bn1=L.BatchNormalization(128),\n","            bn2=L.BatchNormalization(64),\n","            bn3=L.BatchNormalization(32)\n","        )\n","\n","    def __call__(self, z, test=False):\n","        h = F.relu(self.bn0(self.fc(z), test=test))\n","        h = F.reshape(h, (z.shape[0], 256, 2, 2))\n","\n","        h = F.relu(self.bn1(self.dc1(h), test=test))\n","\n","        h = F.relu(self.bn2(self.dc2(h), test=test))\n","\n","        h = F.relu(self.bn3(self.dc3(h), test=test))\n","\n","        h = F.sigmoid(self.dc4(h))\n","\n","        return h\n","\n","\n","class GeneratorResizeConvolution(Chain):\n","    def __init__(self):\n","        super().__init__(\n","            fc=L.Linear(None, 256*2*2),\n","            c1=L.Convolution2D(256, 128, 3, stride=1, pad=1),\n","            c2=L.Convolution2D(128, 64, 3, stride=1, pad=1),\n","            c3=L.Convolution2D(64, 32, 3, stride=1, pad=1),\n","            c4=L.Convolution2D(32, 3, 3, stride=1, pad=1),\n","            bn0=L.BatchNormalization(256*2*2),\n","            bn1=L.BatchNormalization(128),\n","            bn2=L.BatchNormalization(64),\n","            bn3=L.BatchNormalization(32)\n","        )\n","\n","    def __call__(self, z, test=False):\n","        h = F.relu(self.bn0(self.fc(z), test=test))\n","        h = F.reshape(h, (z.shape[0], 256, 2, 2))\n","\n","        # Upsample the image and then apply a dimension preserving convolution\n","        # with a kernel of size (3, 3), stride and padding of size (1, 1).\n","        h = F.unpooling_2d(h, 2, 2, cover_all=False)\n","        h = F.relu(self.bn1(self.c1(h), test=test))\n","\n","        h = F.unpooling_2d(h, 2, 2, cover_all=False)\n","        h = F.relu(self.bn2(self.c2(h), test=test))\n","\n","        h = F.unpooling_2d(h, 2, 2, cover_all=False)\n","        h = F.relu(self.bn3(self.c3(h), test=test))\n","\n","        h = F.unpooling_2d(h, 2, 2, cover_all=False)\n","        h = F.sigmoid(self.c4(h))\n","\n","        return h\n","\n","\n","class Discriminator(Chain):\n","    def __init__(self):\n","        super().__init__(\n","            c0=L.Convolution2D(None, 3, 3, stride=1, pad=1),\n","            c1=L.Convolution2D(3, 32, 4, stride=2, pad=1),\n","            c2=L.Convolution2D(32, 64, 4, stride=2, pad=1),\n","            c3=L.Convolution2D(64, 128, 4, stride=2, pad=1),\n","            c4=L.Convolution2D(128, 256, 4, stride=2, pad=1),\n","            bn1=L.BatchNormalization(32),\n","            bn2=L.BatchNormalization(64),\n","            bn3=L.BatchNormalization(128),\n","            bn4=L.BatchNormalization(256),\n","            fc=L.Linear(None, 2)\n","        )\n","\n","    def __call__(self, x, test=False):\n","        h = F.leaky_relu(self.c0(x))\n","        h = F.leaky_relu(self.bn1(self.c1(h), test=test))\n","        h = F.leaky_relu(self.bn2(self.c2(h), test=test))\n","        h = F.leaky_relu(self.bn3(self.c3(h), test=test))\n","        h = F.leaky_relu(self.bn4(self.c4(h), test=test))\n","        h = self.fc(h)\n","        return h"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L02LCNiub5rA"},"outputs":[],"source":["from keras import layers\n","# Keep default functions.\n","def down_default(filters , kernel_size, apply_batch_normalization = True):\n","    downsample = tf.keras.models.Sequential()\n","    downsample.add(layers.Conv2D(filters,kernel_size,padding = 'same', strides = 2))\n","    if apply_batch_normalization:\n","        downsample.add(layers.BatchNormalization())\n","    downsample.add(keras.layers.LeakyReLU())\n","    return downsample\n","\n","def up_default(filters, kernel_size, dropout = False):\n","    upsample = tf.keras.models.Sequential()\n","    upsample.add(layers.Conv2DTranspose(filters, kernel_size,padding = 'same', strides = 2))\n","    if dropout:\n","        upsample.dropout(0.2)\n","    upsample.add(keras.layers.LeakyReLU())\n","    return upsample\n","\n","# Our new functions.\n","def up_resize_conv(filters, kernel_size, dropout = False):\n","    upsample = tf.keras.models.Sequential()\n","\n","    upsample.add(layers.UpSampling2D(size=(4, 4), data_format=None, interpolation='nearest'))\n","    upsample.add(layers.Conv2D(filters,kernel_size,padding = 'same', strides = 2))\n","\n","    if dropout:\n","        upsample.dropout(0.2)\n","    upsample.add(keras.layers.LeakyReLU())\n","    return upsample\n","\n","def down_upgrade(filters , kernel_size, apply_batch_normalization = True):\n","    return down_default(filters , kernel_size, apply_batch_normalization)\n","\n","# New Interface For model\n","def upgrade(type = \"upgrade\"):\n","    upsample = tf.keras.models.Sequential()\n","    if type == \"upgrade\":\n","        pass\n","    else:\n","        pass\n","    return upsample\n","\n","def up(filters, kernel_size, dropout = False, type = 'resize_conv'):\n","    if type == 'resize_conv':\n","        return up_resize_conv(filters, kernel_size, dropout)\n","    else:\n","        return up_default(filters, kernel_size, dropout)\n","\n","def down(filters , kernel_size, apply_batch_normalization = True, type = \"upgrade\"):\n","    if type == \"upgrade\":\n","        return down_upgrade(filters , kernel_size, apply_batch_normalization)\n","    else:\n","        return down_default(filters , kernel_size, apply_batch_normalization)\n","    \n","def model():\n","    inputs = layers.Input(shape= [SIZE,SIZE,3])\n","    # convolutions down the stack\n","    d1 = down(128,(3,3),False)(inputs)\n","    d2 = down(128,(3,3),False)(d1)\n","    d3 = down(256,(3,3),True)(d2)\n","    d4 = down(512,(3,3),True)(d3)\n","    d5 = down(512,(3,3),True)(d4)\n","    \n","    # deconvolutions up the stack OR first upsampling then convolutions\n","    u1 = up(512,(3,3),False)(d5)\n","    d4_ = upgrade()(d4)\n","    u1 = layers.concatenate([u1,d4_])\n","    u2 = up(256,(3,3),False)(u1)\n","    d3_ = upgrade()(d3)\n","    u2 = layers.concatenate([u2,d3_])\n","    u3 = up(128,(3,3),False)(u2)\n","    d2_ = upgrade()(d2)\n","    u3 = layers.concatenate([u3,d2_])\n","    u4 = up(128,(3,3),False)(u3)\n","    d1_ = upgrade()(d1)\n","    u4 = layers.concatenate([u4,d1_])\n","    u5 = up(3,(3,3),False)(u4)\n","    inputs_ = upgrade()(inputs)\n","    u5 = layers.concatenate([u5,inputs_])\n","    output = layers.Conv2D(3,(2,2),strides = 1, padding = 'same')(u5)\n","    return tf.keras.Model(inputs=inputs, outputs=output)\n","\n","model = model()\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"BPcSkJFRb5rB"},"source":["# Compile"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hZhpT32cb5rB"},"outputs":[],"source":["model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), loss = 'mean_absolute_error',\n","              metrics = ['acc'])"]},{"cell_type":"markdown","metadata":{"id":"mccU7jYNb5rB"},"source":["# Fitting model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tp8mk8FOb5rB"},"outputs":[],"source":["model.fit(train_low_image, train_high_image, epochs = 7, batch_size = 1,\n","          validation_data = (validation_low_image,validation_high_image))"]},{"cell_type":"markdown","metadata":{"id":"sZrsz9KGb5rC"},"source":["# Prediction Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4aTtyyuWb5rC"},"outputs":[],"source":["def plot_images(high,low,predicted):\n","    plt.figure(figsize=(15,15))\n","    plt.subplot(1,3,1)\n","    plt.title('High Image', color = 'green', fontsize = 20)\n","    plt.imshow(high)\n","    plt.subplot(1,3,2)\n","    plt.title('Low Image ', color = 'black', fontsize = 20)\n","    plt.imshow(low)\n","    plt.subplot(1,3,3)\n","    plt.title('Predicted Image ', color = 'Red', fontsize = 20)\n","    plt.imshow(predicted)\n","\n","    plt.show()\n","\n","for i in range(1,10):\n","\n","    predicted = np.clip(model.predict(test_low_image[i].reshape(1,SIZE, SIZE,3)),0.0,1.0).reshape(SIZE, SIZE,3)\n","    plot_images(test_high_image[i],test_low_image[i],predicted)"]},{"cell_type":"markdown","metadata":{"id":"Wg5VRQQxb5rD"},"source":["# Saving model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wKzOaAk_b5rD"},"outputs":[],"source":["model.save(parents_loc + \"final_model.h5\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
